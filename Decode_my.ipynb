{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "110b0b52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-08T13:54:12.269447Z",
     "start_time": "2023-07-08T13:54:11.130062Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe7c8a923d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Optimizer\n",
    "import torch.backends.cudnn as cudnn\n",
    "import tqdm\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader,Subset\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "from models import *\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from util import *\n",
    "import time\n",
    "from my_utils import *\n",
    "\n",
    "\n",
    "random_seed = 0\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02051224",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-08T13:59:28.135773Z",
     "start_time": "2023-07-08T13:59:27.774492Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#The argumention use for surrogate model training stage\n",
    "transform_surrogate_train = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.RandomCrop(32, padding=4),  \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "#The argumention use for all testing set\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "dataset_path = './data/'\n",
    "#外面的数据集加载进来\n",
    "outter_trainset = My_PoisonFolder(1, root=dataset_path + 'tiny-imagenet-200/train/', \\\n",
    "                                  transform=transform_surrogate_train)\n",
    "\n",
    "frog_trainset = My_PoisonFolder(0, root=dataset_path + 'tiny-imagenet-200/frog/', \\\n",
    "                                  transform=transform_surrogate_train)\n",
    "\n",
    "total_set = concoct_dataset(outter_trainset, frog_trainset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44a5745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 350\n",
    "outter_loader = torch.utils.data.DataLoader(total_set, batch_size=train_batch_size, shuffle=True, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "152acb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_loader = torch.utils.data.DataLoader(outter_trainset, batch_size=train_batch_size, shuffle=True, num_workers=16)\n",
    "\n",
    "frog_loader = torch.utils.data.DataLoader(frog_trainset, batch_size=train_batch_size, shuffle=True, num_workers=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db8ab26b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-08T14:11:42.427093Z",
     "start_time": "2023-07-08T14:11:42.283674Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 2 GPUs!\n"
     ]
    }
   ],
   "source": [
    "decode_model = ResNet18_201()\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "    # 将batchsize 30 分配到N个GPU上运行\n",
    "    decode_model = nn.DataParallel(decode_model)\n",
    "device = torch.device(\"cuda:0\" if True else \"cpu\")\n",
    "decode_model = decode_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "150a09b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-08T14:11:50.286973Z",
     "start_time": "2023-07-08T14:11:50.280992Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# outer_opt = torch.optim.RAdam(params=base_model.parameters(), lr=generating_lr_outer)\n",
    "optimizer = torch.optim.SGD(params=decode_model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1daeeb1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, Loss: 0.137, time:24.586 s\n",
      "Epoch:1, Loss: 0.057, time:25.637 s\n",
      "Epoch:2, Loss: 0.063, time:24.446 s\n",
      "Epoch:3, Loss: 0.053, time:24.454 s\n",
      "Epoch:4, Loss: 0.052, time:24.892 s\n",
      "Epoch:5, Loss: 0.052, time:24.960 s\n",
      "Epoch:6, Loss: 0.051, time:24.136 s\n",
      "Epoch:7, Loss: 0.050, time:25.217 s\n",
      "Epoch:8, Loss: 0.049, time:24.925 s\n",
      "Epoch:9, Loss: 0.049, time:24.425 s\n",
      "Epoch:10, Loss: 0.048, time:24.233 s\n",
      "Epoch:11, Loss: 0.047, time:24.500 s\n",
      "Epoch:12, Loss: 0.046, time:24.990 s\n",
      "Epoch:13, Loss: 0.045, time:24.307 s\n",
      "Epoch:14, Loss: 0.044, time:24.588 s\n",
      "Epoch:15, Loss: 0.044, time:25.082 s\n",
      "Epoch:16, Loss: 0.044, time:24.492 s\n",
      "Epoch:17, Loss: 0.042, time:25.239 s\n",
      "Epoch:18, Loss: 0.042, time:24.265 s\n",
      "Epoch:19, Loss: 0.041, time:24.469 s\n",
      "Epoch:20, Loss: 0.040, time:24.639 s\n",
      "Epoch:21, Loss: 0.040, time:24.153 s\n",
      "Epoch:22, Loss: 0.039, time:24.662 s\n",
      "Epoch:23, Loss: 0.039, time:24.077 s\n",
      "Epoch:24, Loss: 0.038, time:24.417 s\n",
      "Epoch:25, Loss: 0.037, time:23.908 s\n",
      "Epoch:26, Loss: 0.037, time:23.979 s\n",
      "Epoch:27, Loss: 0.036, time:24.953 s\n",
      "Epoch:28, Loss: 0.036, time:24.912 s\n",
      "Epoch:29, Loss: 0.034, time:23.887 s\n",
      "Epoch:30, Loss: 0.034, time:24.691 s\n",
      "Epoch:31, Loss: 0.033, time:24.706 s\n",
      "Epoch:32, Loss: 0.033, time:24.969 s\n",
      "Epoch:33, Loss: 0.032, time:24.028 s\n",
      "Epoch:34, Loss: 0.032, time:24.986 s\n",
      "Epoch:35, Loss: 0.031, time:24.563 s\n",
      "Epoch:36, Loss: 0.030, time:24.695 s\n",
      "Epoch:37, Loss: 0.030, time:25.158 s\n",
      "Epoch:38, Loss: 0.029, time:24.477 s\n",
      "Epoch:39, Loss: 0.029, time:24.113 s\n",
      "Epoch:40, Loss: 0.029, time:24.632 s\n",
      "Epoch:41, Loss: 0.027, time:24.521 s\n",
      "Epoch:42, Loss: 0.027, time:25.113 s\n",
      "Epoch:43, Loss: 0.026, time:24.304 s\n",
      "Epoch:44, Loss: 0.026, time:24.726 s\n",
      "Epoch:45, Loss: 0.025, time:24.347 s\n",
      "Epoch:46, Loss: 0.025, time:24.952 s\n",
      "Epoch:47, Loss: 0.024, time:24.190 s\n",
      "Epoch:48, Loss: 0.024, time:24.914 s\n",
      "Epoch:49, Loss: 0.024, time:24.508 s\n",
      "Epoch:50, Loss: 0.022, time:24.390 s\n",
      "Epoch:51, Loss: 0.022, time:24.185 s\n",
      "Epoch:52, Loss: 0.021, time:24.964 s\n",
      "Epoch:53, Loss: 0.021, time:24.812 s\n",
      "Epoch:54, Loss: 0.020, time:24.429 s\n",
      "Epoch:55, Loss: 0.020, time:24.280 s\n",
      "Epoch:56, Loss: 0.020, time:24.256 s\n",
      "Epoch:57, Loss: 0.019, time:24.608 s\n",
      "Epoch:58, Loss: 0.019, time:25.601 s\n",
      "Epoch:59, Loss: 0.018, time:24.421 s\n",
      "Epoch:60, Loss: 0.018, time:25.122 s\n",
      "Epoch:61, Loss: 0.017, time:23.718 s\n",
      "Epoch:62, Loss: 0.016, time:24.654 s\n",
      "Epoch:63, Loss: 0.015, time:24.848 s\n",
      "Epoch:64, Loss: 0.016, time:24.423 s\n",
      "Epoch:65, Loss: 0.015, time:24.815 s\n",
      "Epoch:66, Loss: 0.014, time:24.405 s\n",
      "Epoch:67, Loss: 0.014, time:24.585 s\n",
      "Epoch:68, Loss: 0.013, time:24.260 s\n",
      "Epoch:69, Loss: 0.013, time:25.026 s\n",
      "Epoch:70, Loss: 0.013, time:25.024 s\n",
      "Epoch:71, Loss: 0.011, time:24.087 s\n",
      "Epoch:72, Loss: 0.011, time:25.289 s\n",
      "Epoch:73, Loss: 0.012, time:24.463 s\n",
      "Epoch:74, Loss: 0.011, time:24.192 s\n",
      "Epoch:75, Loss: 0.011, time:24.556 s\n",
      "Epoch:76, Loss: 0.010, time:24.432 s\n",
      "Epoch:77, Loss: 0.010, time:24.673 s\n",
      "Epoch:78, Loss: 0.009, time:24.776 s\n",
      "Epoch:79, Loss: 0.008, time:24.714 s\n",
      "Epoch:80, Loss: 0.008, time:24.571 s\n",
      "Epoch:81, Loss: 0.008, time:25.132 s\n",
      "Epoch:82, Loss: 0.008, time:25.746 s\n",
      "Epoch:83, Loss: 0.007, time:23.524 s\n",
      "Epoch:84, Loss: 0.007, time:24.705 s\n",
      "Epoch:85, Loss: 0.008, time:24.124 s\n",
      "Epoch:86, Loss: 0.006, time:24.499 s\n",
      "Epoch:87, Loss: 0.006, time:24.462 s\n",
      "Epoch:88, Loss: 0.006, time:25.020 s\n",
      "Epoch:89, Loss: 0.006, time:24.887 s\n",
      "Epoch:90, Loss: 0.006, time:24.708 s\n",
      "Epoch:91, Loss: 0.005, time:24.340 s\n",
      "Epoch:92, Loss: 0.004, time:25.950 s\n",
      "Epoch:93, Loss: 0.006, time:23.872 s\n",
      "Epoch:94, Loss: 0.005, time:24.875 s\n",
      "Epoch:95, Loss: 0.004, time:24.510 s\n",
      "Epoch:96, Loss: 0.005, time:24.711 s\n",
      "Epoch:97, Loss: 0.005, time:25.149 s\n",
      "Epoch:98, Loss: 0.004, time:24.576 s\n",
      "Epoch:99, Loss: 0.004, time:24.386 s\n",
      "Epoch:100, Loss: 0.004, time:24.352 s\n",
      "Epoch:101, Loss: 0.003, time:24.703 s\n",
      "Epoch:102, Loss: 0.004, time:24.987 s\n",
      "Epoch:103, Loss: 0.003, time:24.597 s\n",
      "Epoch:104, Loss: 0.003, time:24.949 s\n",
      "Epoch:105, Loss: 0.003, time:24.644 s\n",
      "Epoch:106, Loss: 0.003, time:24.571 s\n",
      "Epoch:107, Loss: 0.003, time:25.243 s\n",
      "Epoch:108, Loss: 0.003, time:24.494 s\n",
      "Epoch:109, Loss: 0.003, time:24.579 s\n",
      "Epoch:110, Loss: 0.002, time:24.787 s\n",
      "Epoch:111, Loss: 0.001, time:24.576 s\n",
      "Epoch:112, Loss: 0.003, time:25.105 s\n",
      "Epoch:113, Loss: 0.003, time:24.453 s\n",
      "Epoch:114, Loss: 0.001, time:24.288 s\n",
      "Epoch:115, Loss: 0.002, time:24.608 s\n",
      "Epoch:116, Loss: 0.002, time:24.530 s\n",
      "Epoch:117, Loss: 0.002, time:25.039 s\n",
      "Epoch:118, Loss: 0.001, time:24.105 s\n",
      "Epoch:119, Loss: 0.001, time:24.921 s\n",
      "Epoch:120, Loss: 0.001, time:24.190 s\n",
      "Epoch:121, Loss: 0.001, time:24.263 s\n",
      "Epoch:122, Loss: 0.001, time:25.346 s\n",
      "Epoch:123, Loss: 0.001, time:24.231 s\n",
      "Epoch:124, Loss: 0.001, time:24.158 s\n",
      "Epoch:125, Loss: 0.001, time:24.445 s\n",
      "Epoch:126, Loss: 0.001, time:24.336 s\n",
      "Epoch:127, Loss: 0.001, time:24.836 s\n",
      "Epoch:128, Loss: 0.001, time:24.786 s\n",
      "Epoch:129, Loss: 0.000, time:24.136 s\n",
      "Epoch:130, Loss: 0.000, time:24.202 s\n",
      "Epoch:131, Loss: 0.000, time:24.280 s\n",
      "Epoch:132, Loss: 0.000, time:24.763 s\n",
      "Epoch:133, Loss: 0.000, time:24.643 s\n",
      "Epoch:134, Loss: 0.000, time:24.472 s\n",
      "Epoch:135, Loss: 0.000, time:24.381 s\n",
      "Epoch:136, Loss: 0.000, time:24.422 s\n",
      "Epoch:137, Loss: 0.000, time:25.023 s\n",
      "Epoch:138, Loss: 0.000, time:24.859 s\n",
      "Epoch:139, Loss: 0.000, time:24.633 s\n",
      "Epoch:140, Loss: 0.000, time:24.561 s\n",
      "Epoch:141, Loss: 0.000, time:24.324 s\n",
      "Epoch:142, Loss: 0.000, time:24.927 s\n",
      "Epoch:143, Loss: 0.000, time:24.420 s\n",
      "Epoch:144, Loss: 0.000, time:24.183 s\n",
      "Epoch:145, Loss: 0.000, time:24.071 s\n",
      "Epoch:146, Loss: 0.000, time:24.126 s\n",
      "Epoch:147, Loss: 0.000, time:24.516 s\n",
      "Epoch:148, Loss: 0.000, time:24.270 s\n",
      "Epoch:149, Loss: 0.000, time:24.345 s\n",
      "Epoch:150, Loss: 0.000, time:24.198 s\n",
      "Epoch:151, Loss: 0.000, time:24.455 s\n",
      "Epoch:152, Loss: 0.000, time:25.045 s\n",
      "Epoch:153, Loss: 0.000, time:24.520 s\n",
      "Epoch:154, Loss: 0.000, time:24.439 s\n",
      "Epoch:155, Loss: 0.000, time:24.647 s\n",
      "Epoch:156, Loss: 0.000, time:24.222 s\n",
      "Epoch:157, Loss: 0.000, time:25.115 s\n",
      "Epoch:158, Loss: 0.000, time:24.196 s\n",
      "Epoch:159, Loss: 0.000, time:24.140 s\n",
      "Epoch:160, Loss: 0.000, time:24.497 s\n",
      "Epoch:161, Loss: 0.000, time:24.035 s\n",
      "Epoch:162, Loss: 0.000, time:25.208 s\n",
      "Epoch:163, Loss: 0.000, time:23.892 s\n",
      "Epoch:164, Loss: 0.000, time:24.099 s\n",
      "Epoch:165, Loss: 0.000, time:24.541 s\n",
      "Epoch:166, Loss: 0.000, time:24.771 s\n",
      "Epoch:167, Loss: 0.000, time:25.467 s\n",
      "Epoch:168, Loss: 0.000, time:24.140 s\n",
      "Epoch:169, Loss: 0.000, time:24.622 s\n",
      "Epoch:170, Loss: 0.000, time:24.369 s\n",
      "Epoch:171, Loss: 0.000, time:25.313 s\n",
      "Epoch:172, Loss: 0.000, time:25.283 s\n",
      "Epoch:173, Loss: 0.000, time:24.084 s\n",
      "Epoch:174, Loss: 0.000, time:25.030 s\n",
      "Epoch:175, Loss: 0.000, time:24.948 s\n",
      "Epoch:176, Loss: 0.000, time:24.490 s\n",
      "Epoch:177, Loss: 0.000, time:24.959 s\n",
      "Epoch:178, Loss: 0.000, time:25.095 s\n",
      "Epoch:179, Loss: 0.000, time:25.010 s\n",
      "Epoch:180, Loss: 0.000, time:24.437 s\n",
      "Epoch:181, Loss: 0.000, time:24.768 s\n",
      "Epoch:182, Loss: 0.000, time:24.564 s\n",
      "Epoch:183, Loss: 0.000, time:24.952 s\n",
      "Epoch:184, Loss: 0.000, time:25.446 s\n",
      "Epoch:185, Loss: 0.000, time:24.491 s\n",
      "Epoch:186, Loss: 0.000, time:24.462 s\n",
      "Epoch:187, Loss: 0.000, time:24.803 s\n",
      "Epoch:188, Loss: 0.000, time:25.228 s\n",
      "Epoch:189, Loss: 0.000, time:24.019 s\n",
      "Epoch:190, Loss: 0.000, time:24.632 s\n",
      "Epoch:191, Loss: 0.000, time:24.752 s\n",
      "Epoch:192, Loss: 0.000, time:25.275 s\n",
      "Epoch:193, Loss: 0.000, time:24.351 s\n",
      "Epoch:194, Loss: 0.000, time:24.380 s\n",
      "Epoch:195, Loss: 0.000, time:23.809 s\n",
      "Epoch:196, Loss: 0.000, time:24.817 s\n",
      "Epoch:197, Loss: 0.000, time:24.856 s\n",
      "Epoch:198, Loss: 0.000, time:24.456 s\n",
      "Epoch:199, Loss: 0.000, time:24.953 s\n"
     ]
    }
   ],
   "source": [
    "time_list = []\n",
    "\n",
    "for epoch in range(0, 200):\n",
    "    since = time.time()\n",
    "    decode_model.train()\n",
    "    loss_list = []\n",
    "    for images, labels in outter_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = decode_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        loss_list.append(float(loss.data))\n",
    "        optimizer.step()\n",
    "        \n",
    "    scheduler.step()\n",
    "    \n",
    "    ave_loss = np.average(np.array(loss_list))\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Epoch:%d, Loss: %.03f, time:%0.3f s' % (epoch, ave_loss, time_elapsed))\n",
    "    since = time.time()\n",
    "    #record time\n",
    "    time_list.append(time_elapsed)\n",
    "#Save the surrogate model\n",
    "save_path = './checkpoint_my/decode_pretrain_binary' + str(200) +'.pth'\n",
    "torch.save(decode_model.state_dict(),save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a602596a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2l.evaluate_accuracy_gpu(decode_model, other_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7ad689",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_3.8",
   "language": "python",
   "name": "python_3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
